<!--
README BEAUTIFIER CHANGES:
- Added compelling tagline and hero section
- Added "Why arkai?" section with pain/solution framing
- Added ASCII architecture diagram
- Added comparison table vs alternatives
- Improved installation with prerequisites inline
- Added quickstart "60-second" section
- Added Mermaid diagrams (collapsible)
- Reorganized for scan-ability
- Added badges
- Kept all original functionality docs
-->

<div align="center">

# arkai

**The production backbone for AI pipelines.**

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Rust](https://img.shields.io/badge/rust-1.70+-orange.svg)](https://www.rust-lang.org/)
[![Fabric](https://img.shields.io/badge/fabric-compatible-green.svg)](https://github.com/danielmiessler/fabric)

*Event-sourced orchestration for [Fabric](https://github.com/danielmiessler/fabric) and beyond.*

[Quick Start](#-quick-start) â€¢ [Why arkai?](#-why-arkai) â€¢ [Features](#-features) â€¢ [Docs](docs/AI_OS_ARCHITECTURE.md)

</div>

---

## The Problem

Building AI workflows today means:
- **Results vanish** after each chat session
- **Pipelines fail** with no way to resume
- **No audit trail** of what happened or why
- **Spaghetti code** as complexity grows

## The Solution

arkai gives your AI a **spine** â€” a Rust-based orchestration layer that:
- **Remembers** everything (event-sourced state)
- **Recovers** from failures (idempotent resume)
- **Replays** any operation (full audit trail)
- **Scales** without spaghetti (YAML pipelines)

---

## ğŸš€ Quick Start

```bash
# Install arkai
cargo install --git https://github.com/arkaigrowth/arkai

# Install Fabric (AI pattern library)
go install github.com/danielmiessler/fabric@latest
fabric --setup

# Ingest your first video
arkai ingest "https://youtube.com/watch?v=..." --tags "ai,learning"

# Search your library
arkai search "transformers"
```

**That's it.** Your knowledge base grows with every ingest.

---

## ğŸ¤” Why arkai?

| Without arkai | With arkai |
|--------------|------------|
| Results vanish after chat | Searchable library forever |
| Pipeline fails â†’ start over | Resume from exact failure point |
| "What did the AI do?" ğŸ¤· | Full event log, replay any step |
| Copy-paste prompt spaghetti | Composable YAML pipelines |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NATURAL LANGUAGE                          â”‚
â”‚              (Claude Code + /arkai skill)                    â”‚
â”‚                                                              â”‚
â”‚   "ingest this video" â†’ arkai ingest "https://..."          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RUST SPINE (arkai)                        â”‚
â”‚              Orchestration â€¢ State â€¢ Reliability             â”‚
â”‚                                                              â”‚
â”‚   âœ“ Event-sourced    âœ“ Idempotent    âœ“ Auditable            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FABRIC (patterns)                         â”‚
â”‚              AI Transformation â€¢ 200+ Prompts                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM PROVIDER                              â”‚
â”‚         (Claude, GPT, Ollama, local models, etc.)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<details>
<summary><b>ğŸ“Š Mermaid: Data Flow</b></summary>

```mermaid
flowchart LR
    subgraph Input
        URL[URL/Text]
    end

    subgraph arkai [arkai Spine]
        ES[Event Store]
        ORCH[Orchestrator]
        CAT[Catalog]
    end

    subgraph Fabric
        PAT[Patterns]
    end

    subgraph Output
        LIB[Library]
    end

    URL --> ORCH
    ORCH --> ES
    ORCH --> PAT
    PAT --> ORCH
    ORCH --> CAT
    ORCH --> LIB
```

</details>

<details>
<summary><b>ğŸ“Š Mermaid: Event Sourcing</b></summary>

```mermaid
sequenceDiagram
    participant User
    participant arkai
    participant EventStore
    participant Fabric
    participant LLM

    User->>arkai: ingest URL
    arkai->>EventStore: RunStarted
    arkai->>Fabric: fetch transcript
    Fabric->>LLM: extract_wisdom
    LLM-->>Fabric: wisdom.md
    arkai->>EventStore: StepCompleted
    arkai->>User: âœ… Content ingested

    Note over EventStore: Full replay possible
```

</details>

---

## âœ¨ Features

### Content Ingestion
```bash
# YouTube (auto-detected)
arkai ingest "https://youtube.com/watch?v=..." --tags "ai,ml"

# Web articles
arkai ingest "https://example.com/article" --tags "tech"
```

### Massive Context Analysis (RLM)
```bash
# Analyze entire repositories that exceed context windows
# Uses Recursive Language Model (MIT paper: arxiv.org/html/2512.24601v1)

# In Claude Code, RLM tools are available as MCP:
rlm_load_context      # Load files as external variables
rlm_filter_context    # Regex-based filtering (deterministic)
rlm_sub_query         # LLM call on chunks (budgeted)
rlm_exec             # Sandboxed Python execution (HITL)
```

### Searchable Library
```bash
arkai library                    # List all
arkai library --content-type youtube  # Filter
arkai search "transformer"       # Full-text search
arkai show <id> --full           # View content
```

### Pipeline Orchestration
```bash
arkai run my-pipeline            # Execute pipeline
arkai status <run_id>            # Check status
arkai resume <run_id>            # Resume failed run
```

### Debug & Observability
```bash
arkai config                     # Show resolved paths
arkai runs                       # List recent runs
```

---

## ğŸ“ Project Structure

```
your-project/
â”œâ”€â”€ .arkai/
â”‚   â”œâ”€â”€ config.yaml        # Project config
â”‚   â”œâ”€â”€ catalog.json       # Searchable index
â”‚   â””â”€â”€ runs/              # Event logs (gitignore)
â”‚
â”œâ”€â”€ library/               # Knowledge base (git-track!)
â”‚   â”œâ”€â”€ youtube/
â”‚   â””â”€â”€ articles/
â”‚
â””â”€â”€ pipelines/             # Custom workflows
    â””â”€â”€ my-workflow.yaml
```

---

## ğŸ“ Pipeline Definition

```yaml
name: youtube-wisdom
description: Extract wisdom from YouTube videos

safety_limits:
  max_steps: 10
  step_timeout_seconds: 300

steps:
  - name: fetch
    action: __youtube__
    input_from: pipeline_input

  - name: wisdom
    action: extract_wisdom
    input_from: fetch

  - name: summary
    action: summarize
    input_from: wisdom
```

---

## ğŸ”„ Comparison

| Feature | Raw LLM | LangChain | Fabric | **arkai + Fabric** |
|---------|---------|-----------|--------|-------------------|
| Persistent state | âŒ | âš ï¸ | âŒ | âœ… |
| Resume failed runs | âŒ | âŒ | âŒ | âœ… |
| Full audit trail | âŒ | âŒ | âŒ | âœ… |
| 200+ AI patterns | âŒ | âš ï¸ | âœ… | âœ… |
| Content library | âŒ | âŒ | âŒ | âœ… |
| Single binary | âŒ | âŒ | âœ… | âœ… |
| Massive context (RLM) | âŒ | âš ï¸ | âŒ | âœ… |
| Evidence provenance | âŒ | âŒ | âŒ | âœ… |

---

## ğŸ“š Documentation

- [AI OS Architecture](docs/AI_OS_ARCHITECTURE.md) â€” Full philosophy and design
- [Pitch](docs/PITCH.md) â€” Quick shareable summary
- [Architecture Overview](ai_docs/architecture/overview.md) â€” Technical deep-dive

---

## ğŸ› ï¸ Prerequisites

- **Rust 1.70+** â€” [Install](https://rustup.rs/)
- **Fabric** â€” [Install](https://github.com/danielmiessler/fabric#installation)
- **LLM API key** â€” Configure via `fabric --setup`

---

## ğŸ“œ License

MIT â€” Use it, fork it, build on it.

---

<div align="center">

**Built with ğŸ¦€ Rust + ğŸ§µ Fabric**

*"A really smart AI with a bad system is way worse than a well-designed system with a less smart model."*

</div>
